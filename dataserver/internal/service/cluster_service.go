package service

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"strings"
	"time"

	"dataserver/internal/model"
	"dataserver/pb"

	clientv3 "go.etcd.io/etcd/client/v3"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"
)

// EtcdClusterService etcdé›†ç¾¤æœåŠ¡å®ç°
type EtcdClusterService struct {
	config         *model.Config
	etcdClient     *clientv3.Client
	metaClient     *grpc.ClientConn
	storageService model.StorageService
	
	// ç§Ÿçº¦ç®¡ç†
	lease          clientv3.Lease
	leaseID        clientv3.LeaseID
	
	// æ§åˆ¶å¾ªç¯
	stopChan       chan struct{}
	isRunning      bool
	
	// Leaderå‘ç°å’Œç›‘å¬
	currentLeader  string
	leaderWatcher  clientv3.WatchChan
	leaderStopChan chan struct{}
}

// NewClusterService åˆ›å»ºé›†ç¾¤æœåŠ¡å®ä¾‹
func NewClusterService(config *model.Config, storageService model.StorageService) (*EtcdClusterService, error) {
	// åˆ›å»ºetcdå®¢æˆ·ç«¯
	etcdClient, err := clientv3.New(clientv3.Config{
		Endpoints:   config.Etcd.Endpoints,
		DialTimeout: time.Duration(config.Etcd.DialTimeout) * time.Second,
	})
	if err != nil {
		return nil, fmt.Errorf("failed to create etcd client: %w", err)
	}
	
	// å‘ç°å½“å‰Leader
	leader, err := discoverLeader(etcdClient)
	if err != nil {
		etcdClient.Close()
		return nil, fmt.Errorf("failed to discover leader: %w", err)
	}
	
	// åˆ›å»ºmetaserverè¿æ¥åˆ°Leader
	ctx, cancel := context.WithTimeout(context.Background(), 
		time.Duration(config.MetaServer.ConnectionTimeout)*time.Second)
	defer cancel()
	
	metaConn, err := grpc.DialContext(ctx, leader,
		grpc.WithTransportCredentials(insecure.NewCredentials()),
	)
	if err != nil {
		etcdClient.Close()
		return nil, fmt.Errorf("failed to connect to leader metaserver %s: %w", leader, err)
	}
	
	service := &EtcdClusterService{
		config:         config,
		etcdClient:     etcdClient,
		metaClient:     metaConn,
		storageService: storageService,
		lease:          clientv3.NewLease(etcdClient),
		stopChan:       make(chan struct{}),
		leaderStopChan: make(chan struct{}),
		currentLeader:  leader,
	}
	
	// å¯åŠ¨Leaderç›‘å¬
	service.startLeaderWatcher()
	
	return service, nil
}

// RegisterToETCD åœ¨etcdä¸­æ³¨å†Œæœ¬æœåŠ¡
func (s *EtcdClusterService) RegisterToETCD() error {
	ctx := context.Background()
	
	// åˆ›å»ºç§Ÿçº¦
	ttl := s.config.Etcd.LeaseTTL
	leaseResp, err := s.lease.Grant(ctx, ttl)
	if err != nil {
		return fmt.Errorf("failed to grant lease: %w", err)
	}
	
	s.leaseID = leaseResp.ID
	
	// æ³¨å†ŒæœåŠ¡key
	key := fmt.Sprintf("/dfs/dataserver/%s", s.config.Server.DataserverId)
	value := fmt.Sprintf("%s", s.config.Server.ListenAddress)
	
	_, err = s.etcdClient.Put(ctx, key, value, clientv3.WithLease(s.leaseID))
	if err != nil {
		return fmt.Errorf("failed to register service: %w", err)
	}
	
	// å¯åŠ¨ç§Ÿçº¦ç»­æœŸ
	ch, kaerr := s.lease.KeepAlive(ctx, s.leaseID)
	if kaerr != nil {
		return fmt.Errorf("failed to keep alive lease: %w", kaerr)
	}
	
	// å¯åŠ¨åå°goroutineå¤„ç†ç§Ÿçº¦ç»­æœŸå“åº”
	go func() {
		for ka := range ch {
			if ka == nil {
				log.Println("Lease keep-alive channel closed")
				return
			}
			// å¯ä»¥åœ¨è¿™é‡Œè®°å½•æ—¥å¿—æˆ–å¤„ç†ç»­æœŸå“åº”
		}
	}()
	
	log.Printf("Successfully registered to etcd: %s -> %s", key, value)
	return nil
}

// StartHeartbeatLoop å¯åŠ¨å¿ƒè·³å¾ªç¯
func (s *EtcdClusterService) StartHeartbeatLoop() error {
	if s.isRunning {
		return fmt.Errorf("heartbeat loop is already running")
	}
	
	s.isRunning = true
	
	// å¯åŠ¨å¿ƒè·³goroutine
	go s.heartbeatLoop()
	
	log.Println("Heartbeat loop started")
	return nil
}

// startLeaderWatcher å¯åŠ¨Leaderå˜åŒ–ç›‘å¬
func (s *EtcdClusterService) startLeaderWatcher() {
	// ç›‘å¬Leaderå˜åŒ– - ç›‘å¬å…·ä½“çš„leader key
	s.leaderWatcher = s.etcdClient.Watch(context.Background(), "/dfs/metaserver/leader/current")
	
	go func() {
		log.Println("Leader watcher started, monitoring /dfs/metaserver/leader/current")
		
		for {
			select {
			case watchResp := <-s.leaderWatcher:
				for _, event := range watchResp.Events {
					log.Printf("Leader change detected: %s on key %s, value: %s", 
						event.Type, string(event.Kv.Key), string(event.Kv.Value))
					
					// å½“Leaderå‘ç”Ÿå˜åŒ–æ—¶ï¼Œé‡æ–°è¿æ¥
					if err := s.handleLeaderChange(); err != nil {
						log.Printf("Failed to handle leader change: %v", err)
					} else {
						log.Printf("Successfully handled leader change")
					}
				}
				
			case <-s.leaderStopChan:
				log.Println("Leader watcher stopping")
				return
			}
		}
	}()
}

// handleLeaderChange å¤„ç†Leaderå˜åŒ–
func (s *EtcdClusterService) handleLeaderChange() error {
	log.Println("Handling leader change...")
	
	// å‘ç°æ–°çš„Leader
	newLeader, err := discoverLeader(s.etcdClient)
	if err != nil {
		return fmt.Errorf("failed to discover new leader: %w", err)
	}
	
	if newLeader == s.currentLeader {
		log.Printf("Leader unchanged: %s", s.currentLeader)
		return nil // æ²¡æœ‰å˜åŒ–
	}
	
	log.Printf("Leader changed from %s to %s, reconnecting...", s.currentLeader, newLeader)
	
	// å…³é—­æ—§è¿æ¥
	if s.metaClient != nil {
		s.metaClient.Close()
	}
	
	// åˆ›å»ºæ–°è¿æ¥
	ctx, cancel := context.WithTimeout(context.Background(), 
		time.Duration(s.config.MetaServer.ConnectionTimeout)*time.Second)
	defer cancel()
	
	newConn, err := grpc.DialContext(ctx, newLeader,
		grpc.WithTransportCredentials(insecure.NewCredentials()),
	)
	if err != nil {
		return fmt.Errorf("failed to connect to new leader %s: %w", newLeader, err)
	}
	
	s.metaClient = newConn
	s.currentLeader = newLeader
	
	log.Printf("Successfully reconnected to new leader: %s", newLeader)
	return nil
}

// Stop åœæ­¢é›†ç¾¤æœåŠ¡
func (s *EtcdClusterService) Stop() error {
	if !s.isRunning {
		return nil
	}
	
	// åœæ­¢Leaderç›‘å¬
	close(s.leaderStopChan)
	
	// åœæ­¢å¿ƒè·³å¾ªç¯
	close(s.stopChan)
	s.isRunning = false
	
	// æ’¤é”€ç§Ÿçº¦
	if s.leaseID != 0 {
		ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
		defer cancel()
		
		_, err := s.lease.Revoke(ctx, s.leaseID)
		if err != nil {
			log.Printf("Failed to revoke lease: %v", err)
		}
	}
	
	// å…³é—­è¿æ¥
	if s.metaClient != nil {
		s.metaClient.Close()
	}
	
	if s.etcdClient != nil {
		s.etcdClient.Close()
	}
	
	log.Println("Cluster service stopped")
	return nil
}

// heartbeatLoop å¿ƒè·³å¾ªç¯å®ç°
func (s *EtcdClusterService) heartbeatLoop() {
	ticker := time.NewTicker(time.Duration(s.config.MetaServer.HeartbeatInterval) * time.Second)
	defer ticker.Stop()
	
	for {
		select {
		case <-ticker.C:
			if err := s.sendHeartbeat(); err != nil {
				log.Printf("Failed to send heartbeat: %v", err)
			}
			
		case <-s.stopChan:
			log.Println("Heartbeat loop stopping")
			return
		}
	}
}

// sendHeartbeat å‘é€å¿ƒè·³åˆ°metaserver
func (s *EtcdClusterService) sendHeartbeat() error {
	// è·å–å­˜å‚¨ç»Ÿè®¡
	stat, err := s.storageService.GetStat()
	if err != nil {
		return fmt.Errorf("failed to get storage stat: %w", err)
	}
	
	// åˆ›å»ºmetaserverå®¢æˆ·ç«¯
	client := NewMetaServerServiceClient(s.metaClient)
	
	// æ„å»ºå¿ƒè·³è¯·æ±‚
	req := &pb.HeartbeatRequest{
		DataserverId:   s.config.Server.DataserverId,
		DataserverAddr: s.config.Server.ListenAddress,
		BlockCount:     stat.BlockCount,
		FreeSpace:      stat.FreeSpace,
		BlockIdsReport: stat.BlockIds,
		TotalCapacity:  stat.TotalCapacity,
	}
	
	// æ‰“å°å¿ƒè·³è¯·æ±‚æ•°æ®åˆ°æ§åˆ¶å°
	log.Printf("ğŸ“¡ [HEARTBEAT REQUEST] DataServer: %s", req.DataserverId)
	log.Printf("    â””â”€â”€ Address: %s", req.DataserverAddr)
	log.Printf("    â””â”€â”€ Block Count: %d", req.BlockCount)
	log.Printf("    â””â”€â”€ Free Space: %d bytes (%.2f MB)", req.FreeSpace, float64(req.FreeSpace)/(1024*1024))
	if len(req.BlockIdsReport) > 0 {
		if len(req.BlockIdsReport) <= 10 {
			log.Printf("    â””â”€â”€ Block IDs: %v", req.BlockIdsReport)
		} else {
			log.Printf("    â””â”€â”€ Block IDs: %v... (total: %d blocks)", req.BlockIdsReport[:10], len(req.BlockIdsReport))
		}
	} else {
		log.Printf("    â””â”€â”€ Block IDs: [] (no blocks stored)")
	}
	
	// å‘é€å¿ƒè·³
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()
	
	resp, err := client.Heartbeat(ctx, req)
	if err != nil {
		log.Printf("Heartbeat failed, attempting to reconnect to leader: %v", err)
		// å°è¯•é‡è¿åˆ°æ–°çš„Leader
		if reconnectErr := s.reconnectToLeader(); reconnectErr != nil {
			return fmt.Errorf("failed to reconnect to leader: %w", reconnectErr)
		}
		
		// é‡æ–°åˆ›å»ºå®¢æˆ·ç«¯å¹¶é‡è¯•
		client = NewMetaServerServiceClient(s.metaClient)
		ctx, cancel = context.WithTimeout(context.Background(), 5*time.Second)
		defer cancel()
		
		resp, err = client.Heartbeat(ctx, req)
		if err != nil {
			return fmt.Errorf("failed to send heartbeat after reconnect: %w", err)
		}
	}
	
	// æ‰“å°å¿ƒè·³å“åº”æ•°æ®åˆ°æ§åˆ¶å°
	log.Printf("ğŸ’“ [HEARTBEAT RESPONSE] Commands received: %d", len(resp.Commands))
	if len(resp.Commands) > 0 {
		for i, cmd := range resp.Commands {
			actionName := "UNKNOWN"
			switch cmd.Action {
			case pb.Command_DELETE_BLOCK:
				actionName = "DELETE_BLOCK"
			case pb.Command_COPY_BLOCK:
				actionName = "COPY_BLOCK"
			}
			log.Printf("    â””â”€â”€ Command %d: %s (Block ID: %d)", i+1, actionName, cmd.BlockId)
			if len(cmd.Targets) > 0 {
				log.Printf("        â””â”€â”€ Targets: %v", cmd.Targets)
			}
		}
		go s.processCommands(resp.Commands)
	} else {
		log.Printf("    â””â”€â”€ No commands from MetaServer")
	}
	
	return nil
}

// processCommands å¤„ç†æ¥è‡ªmetaserverçš„å‘½ä»¤
func (s *EtcdClusterService) processCommands(commands []*pb.Command) {
	for _, cmd := range commands {
		if err := s.processCommand(cmd); err != nil {
			log.Printf("Failed to process command: %v", err)
		}
	}
}

// processCommand å¤„ç†å•ä¸ªå‘½ä»¤
func (s *EtcdClusterService) processCommand(cmd *pb.Command) error {
	switch cmd.Action {
	case pb.Command_DELETE_BLOCK:
		return s.processDeleteCommand(cmd.BlockId)
		
	case pb.Command_COPY_BLOCK:
		return s.processReplicateCommand(cmd.BlockId, cmd.Targets)
		
	default:
		return fmt.Errorf("unknown command action: %d", cmd.Action)
	}
}

// processDeleteCommand å¤„ç†åˆ é™¤å—å‘½ä»¤
func (s *EtcdClusterService) processDeleteCommand(blockID uint64) error {
	log.Printf("Processing delete command for block %d", blockID)
	
	if err := s.storageService.DeleteBlock(blockID); err != nil {
		return fmt.Errorf("failed to delete block %d: %w", blockID, err)
	}
	
	log.Printf("Successfully deleted block %d", blockID)
	return nil
}

// processReplicateCommand å¤„ç†å¤åˆ¶å—å‘½ä»¤ - ä»æºåœ°å€å¤åˆ¶æ•°æ®åˆ°æœ¬åœ°
func (s *EtcdClusterService) processReplicateCommand(blockID uint64, targets []string) error {
	if len(targets) == 0 {
		return fmt.Errorf("no source address provided for block %d replication", blockID)
	}
	
	sourceAddr := targets[0] // targets[0] æ˜¯æºåœ°å€
	log.Printf("Processing replicate command for block %d from source: %s", blockID, sourceAddr)
	
	// è¿æ¥åˆ°æºDataServer
	conn, err := grpc.Dial(sourceAddr, grpc.WithTransportCredentials(insecure.NewCredentials()))
	if err != nil {
		return fmt.Errorf("failed to connect to source %s: %w", sourceAddr, err)
	}
	defer conn.Close()
	
	client := pb.NewDataServerServiceClient(conn)
	
	// ä»æºåœ°å€è¯»å–å—æ•°æ®
	req := &pb.ReadBlockRequest{
		BlockId: blockID,
	}
	
	stream, err := client.ReadBlock(context.Background(), req)
	if err != nil {
		return fmt.Errorf("failed to read block %d from source %s: %w", blockID, sourceAddr, err)
	}
	
	var blockData []byte
	for {
		resp, err := stream.Recv()
		if err == io.EOF {
			break
		}
		if err != nil {
			return fmt.Errorf("failed to receive block data: %w", err)
		}
		blockData = append(blockData, resp.ChunkData...)
	}
	
	// å°†æ•°æ®å†™å…¥æœ¬åœ°å­˜å‚¨
	if err := s.storageService.WriteBlock(blockID, blockData); err != nil {
		return fmt.Errorf("failed to write block %d locally: %w", blockID, err)
	}
	
	log.Printf("Successfully replicated block %d from %s (%d bytes)", blockID, sourceAddr, len(blockData))
	return nil
}

// discoverLeader ä»etcdå‘ç°å½“å‰Leader
func discoverLeader(etcdClient *clientv3.Client) (string, error) {
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()
	
	// æŸ¥è¯¢etcdä¸­çš„Leaderä¿¡æ¯
	resp, err := etcdClient.Get(ctx, "/dfs/metaserver/leader/current")
	if err != nil {
		return "", fmt.Errorf("failed to query leader from etcd: %w", err)
	}
	
	if len(resp.Kvs) == 0 {
		return "", fmt.Errorf("no leader found in etcd")
	}
	
	// Leaderçš„åœ°å€ä»keyä¸­æå–èŠ‚ç‚¹IDï¼Œç„¶åæŸ¥è¯¢èŠ‚ç‚¹ä¿¡æ¯
	leaderNodeID := string(resp.Kvs[0].Value)
	log.Printf("Found leader node ID: %s", leaderNodeID)
	
	// æŸ¥è¯¢èŠ‚ç‚¹ä¿¡æ¯
	nodeResp, err := etcdClient.Get(ctx, fmt.Sprintf("/dfs/metaserver/nodes/%s", leaderNodeID))
	if err != nil {
		return "", fmt.Errorf("failed to get leader node info: %w", err)
	}
	
	if len(nodeResp.Kvs) == 0 {
		return "", fmt.Errorf("leader node info not found")
	}
	
	// è§£æèŠ‚ç‚¹åœ°å€ - åº”è¯¥æ˜¯JSONæ ¼å¼
	nodeInfo := string(nodeResp.Kvs[0].Value)
	log.Printf("Leader node info: %s", nodeInfo)
	
	// å°è¯•è§£æJSONæ ¼å¼
	var node struct {
		Addr string `json:"addr"`
	}
	
	if err := json.Unmarshal([]byte(nodeInfo), &node); err == nil && node.Addr != "" {
		log.Printf("Discovered leader address: %s", node.Addr)
		return node.Addr, nil
	}
	
	// å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•ç®€å•çš„å­—ç¬¦ä¸²è§£æ
	if strings.Contains(nodeInfo, "\"addr\":\"") {
		// JSONæ ¼å¼ï¼Œæå–addrå­—æ®µ
		parts := strings.Split(nodeInfo, "\"addr\":\"")
		if len(parts) > 1 {
			addr := strings.Split(parts[1], "\"")[0]
			log.Printf("Parsed leader address: %s", addr)
			return addr, nil
		}
	}
	
	// å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨èŠ‚ç‚¹ä¿¡æ¯ä½œä¸ºåœ°å€
	log.Printf("Using node info as address: %s", nodeInfo)
	return nodeInfo, nil
}

// reconnectToLeader é‡è¿åˆ°æ–°çš„Leader
func (s *EtcdClusterService) reconnectToLeader() error {
	// å‘ç°æ–°çš„Leader
	newLeader, err := discoverLeader(s.etcdClient)
	if err != nil {
		return fmt.Errorf("failed to discover new leader: %w", err)
	}
	
	if newLeader == s.currentLeader {
		return nil // æ²¡æœ‰å˜åŒ–
	}
	
	log.Printf("Leader changed from %s to %s, reconnecting...", s.currentLeader, newLeader)
	
	// å…³é—­æ—§è¿æ¥
	if s.metaClient != nil {
		s.metaClient.Close()
	}
	
	// åˆ›å»ºæ–°è¿æ¥
	ctx, cancel := context.WithTimeout(context.Background(), 
		time.Duration(s.config.MetaServer.ConnectionTimeout)*time.Second)
	defer cancel()
	
	newConn, err := grpc.DialContext(ctx, newLeader,
		grpc.WithTransportCredentials(insecure.NewCredentials()),
	)
	if err != nil {
		return fmt.Errorf("failed to connect to new leader %s: %w", newLeader, err)
	}
	
	s.metaClient = newConn
	s.currentLeader = newLeader
	
	log.Printf("Successfully reconnected to new leader: %s", newLeader)
	return nil
}

// ä½¿ç”¨ç”Ÿæˆçš„MetaServerå®¢æˆ·ç«¯
func NewMetaServerServiceClient(conn *grpc.ClientConn) pb.MetaServerServiceClient {
	return pb.NewMetaServerServiceClient(conn)
}
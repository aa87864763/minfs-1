package service

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"strings"
	"time"

	"dataServer/internal/model"
	"dataServer/pb"

	clientv3 "go.etcd.io/etcd/client/v3"
	"go.etcd.io/etcd/client/v3/concurrency"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"
)

// EtcdClusterService etcdé›†ç¾¤æœåŠ¡å®ç°
type EtcdClusterService struct {
	config         *model.Config
	etcdClient     *clientv3.Client
	metaClient     *grpc.ClientConn
	storageService model.StorageService

	// ç§Ÿçº¦ç®¡ç†
	lease   clientv3.Lease
	leaseID clientv3.LeaseID

	// æ§åˆ¶å¾ªç¯
	stopChan  chan struct{}
	isRunning bool

	// Leaderå‘ç°å’Œç›‘å¬
	currentLeader  string
	leaderWatcher  clientv3.WatchChan
	leaderStopChan chan struct{}
}

// NewClusterService åˆ›å»ºé›†ç¾¤æœåŠ¡å®ä¾‹
func NewClusterService(config *model.Config, storageService model.StorageService) (*EtcdClusterService, error) {
	// åˆ›å»ºetcdå®¢æˆ·ç«¯
	etcdClient, err := clientv3.New(clientv3.Config{
		Endpoints:   config.Etcd.Endpoints,
		DialTimeout: time.Duration(config.Etcd.DialTimeout) * time.Second,
	})
	if err != nil {
		return nil, fmt.Errorf("failed to create etcd client: %w", err)
	}

	// å‘ç°å½“å‰Leader
	leader, err := discoverLeader(etcdClient)
	if err != nil {
		etcdClient.Close()
		return nil, fmt.Errorf("failed to discover leader: %w", err)
	}

	// åˆ›å»ºmetaServerè¿æ¥åˆ°Leader
	ctx, cancel := context.WithTimeout(context.Background(),
		time.Duration(config.MetaServer.ConnectionTimeout)*time.Second)
	defer cancel()

	metaConn, err := grpc.DialContext(ctx, leader,
		grpc.WithTransportCredentials(insecure.NewCredentials()),
	)
	if err != nil {
		etcdClient.Close()
		return nil, fmt.Errorf("failed to connect to leader metaServer %s: %w", leader, err)
	}

	service := &EtcdClusterService{
		config:         config,
		etcdClient:     etcdClient,
		metaClient:     metaConn,
		storageService: storageService,
		lease:          clientv3.NewLease(etcdClient),
		stopChan:       make(chan struct{}),
		leaderStopChan: make(chan struct{}),
		currentLeader:  leader,
	}

	// å¯åŠ¨Leaderç›‘å¬
	service.startLeaderWatcher()

	return service, nil
}

// RegisterToETCD åœ¨etcdä¸­æ³¨å†Œæœ¬æœåŠ¡
func (s *EtcdClusterService) RegisterToETCD() error {
	ctx := context.Background()

	// åˆ›å»ºç§Ÿçº¦
	ttl := s.config.Etcd.LeaseTTL
	leaseResp, err := s.lease.Grant(ctx, ttl)
	if err != nil {
		return fmt.Errorf("failed to grant lease: %w", err)
	}

	s.leaseID = leaseResp.ID

	// æ³¨å†ŒæœåŠ¡key - ä½¿ç”¨ä¸metaServeré…ç½®åŒ¹é…çš„å‰ç¼€
	key := fmt.Sprintf("/dfs/dataServers/%s", s.config.Server.DataserverId)
	value := fmt.Sprintf("%s", s.config.Server.ListenAddress)

	_, err = s.etcdClient.Put(ctx, key, value, clientv3.WithLease(s.leaseID))
	if err != nil {
		return fmt.Errorf("failed to register service: %w", err)
	}

	// å¯åŠ¨ç§Ÿçº¦ç»­æœŸ
	ch, kaerr := s.lease.KeepAlive(ctx, s.leaseID)
	if kaerr != nil {
		return fmt.Errorf("failed to keep alive lease: %w", kaerr)
	}

	// å¯åŠ¨åå°goroutineå¤„ç†ç§Ÿçº¦ç»­æœŸå“åº”
	go func() {
		for ka := range ch {
			if ka == nil {
				log.Println("Lease keep-alive channel closed")
				return
			}
			// å¯ä»¥åœ¨è¿™é‡Œè®°å½•æ—¥å¿—æˆ–å¤„ç†ç»­æœŸå“åº”
		}
	}()

	log.Printf("Successfully registered to etcd: %s -> %s", key, value)
	return nil
}

// StartHeartbeatLoop å¯åŠ¨å¿ƒè·³å¾ªç¯
func (s *EtcdClusterService) StartHeartbeatLoop() error {
	if s.isRunning {
		return fmt.Errorf("heartbeat loop is already running")
	}

	s.isRunning = true

	// å¯åŠ¨å¿ƒè·³goroutine
	go s.heartbeatLoop()

	log.Println("Heartbeat loop started")
	return nil
}

// startLeaderWatcher å¯åŠ¨Leaderå˜åŒ–ç›‘å¬
func (s *EtcdClusterService) startLeaderWatcher() {
	// ç›‘å¬Leaderå˜åŒ– - ä½¿ç”¨æ–°çš„electionè·¯å¾„
	s.leaderWatcher = s.etcdClient.Watch(context.Background(), "/minfs/metaServer/election/", clientv3.WithPrefix())

	go func() {
		log.Println("Leader watcher started, monitoring /minfs/metaServer/election/")

		for {
			select {
			case watchResp := <-s.leaderWatcher:
				for _, event := range watchResp.Events {
					log.Printf("Leader change detected: %s on key %s, value: %s",
						event.Type, string(event.Kv.Key), string(event.Kv.Value))

					// å½“Leaderå‘ç”Ÿå˜åŒ–æ—¶ï¼Œé‡æ–°è¿æ¥
					if err := s.handleLeaderChange(); err != nil {
						log.Printf("Failed to handle leader change: %v", err)
					} else {
						log.Printf("Successfully handled leader change")
					}
				}

			case <-s.leaderStopChan:
				log.Println("Leader watcher stopping")
				return
			}
		}
	}()
}

// handleLeaderChange å¤„ç†Leaderå˜åŒ–
func (s *EtcdClusterService) handleLeaderChange() error {
	log.Println("Handling leader change...")

	// å‘ç°æ–°çš„Leader
	newLeader, err := discoverLeader(s.etcdClient)
	if err != nil {
		return fmt.Errorf("failed to discover new leader: %w", err)
	}

	if newLeader == s.currentLeader {
		log.Printf("Leader unchanged: %s", s.currentLeader)
		return nil // æ²¡æœ‰å˜åŒ–
	}

	log.Printf("Leader changed from %s to %s, reconnecting...", s.currentLeader, newLeader)

	// å…³é—­æ—§è¿æ¥
	if s.metaClient != nil {
		s.metaClient.Close()
	}

	// åˆ›å»ºæ–°è¿æ¥
	ctx, cancel := context.WithTimeout(context.Background(),
		time.Duration(s.config.MetaServer.ConnectionTimeout)*time.Second)
	defer cancel()

	newConn, err := grpc.DialContext(ctx, newLeader,
		grpc.WithTransportCredentials(insecure.NewCredentials()),
	)
	if err != nil {
		return fmt.Errorf("failed to connect to new leader %s: %w", newLeader, err)
	}

	s.metaClient = newConn
	s.currentLeader = newLeader

	log.Printf("Successfully reconnected to new leader: %s", newLeader)
	return nil
}

// Stop åœæ­¢é›†ç¾¤æœåŠ¡ (æ³¨æ„ï¼šetcdæ³¨é”€åº”åœ¨è°ƒç”¨æ­¤æ–¹æ³•å‰å®Œæˆ)
func (s *EtcdClusterService) Stop() error {
	if !s.isRunning {
		return nil
	}

	log.Println("Stopping cluster service...")

	// åœæ­¢Leaderç›‘å¬
	close(s.leaderStopChan)

	// åœæ­¢å¿ƒè·³å¾ªç¯
	close(s.stopChan)
	s.isRunning = false

	// å…³é—­ç§Ÿçº¦å®¢æˆ·ç«¯ (ç§Ÿçº¦åº”è¯¥å·²ç»åœ¨DeregisterFromETCDä¸­æ’¤é”€)
	if s.lease != nil {
		s.lease.Close()
	}

	// å…³é—­è¿æ¥
	if s.metaClient != nil {
		s.metaClient.Close()
	}

	if s.etcdClient != nil {
		s.etcdClient.Close()
	}

	log.Println("Cluster service stopped successfully")
	return nil
}

// heartbeatLoop å¿ƒè·³å¾ªç¯å®ç°
func (s *EtcdClusterService) heartbeatLoop() {
	ticker := time.NewTicker(time.Duration(s.config.MetaServer.HeartbeatInterval) * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			if err := s.sendHeartbeat(); err != nil {
				log.Printf("Failed to send heartbeat: %v", err)
			}

		case <-s.stopChan:
			log.Println("Heartbeat loop stopping")
			return
		}
	}
}

// sendHeartbeat å‘é€å¿ƒè·³åˆ°metaServer
func (s *EtcdClusterService) sendHeartbeat() error {
	// è·å–å­˜å‚¨ç»Ÿè®¡
	stat, err := s.storageService.GetStat()
	if err != nil {
		return fmt.Errorf("failed to get storage stat: %w", err)
	}

	// åˆ›å»ºmetaServerå®¢æˆ·ç«¯
	client := NewMetaServerServiceClient(s.metaClient)

	// æ„å»ºå¿ƒè·³è¯·æ±‚
	req := &pb.HeartbeatRequest{
		DataserverId:   s.config.Server.DataserverId,
		DataserverAddr: s.config.Server.ListenAddress,
		BlockCount:     stat.BlockCount,
		FreeSpace:      stat.FreeSpace,
		BlockIdsReport: stat.BlockIds,
		TotalCapacity:  stat.TotalCapacity,
	}

	// æ‰“å°å¿ƒè·³è¯·æ±‚æ•°æ®åˆ°æ§åˆ¶å°
	log.Printf("ğŸ“¡ [HEARTBEAT REQUEST] DataServer: %s", req.DataserverId)
	log.Printf("    â””â”€â”€ Address: %s", req.DataserverAddr)
	log.Printf("    â””â”€â”€ Block Count: %d", req.BlockCount)
	log.Printf("    â””â”€â”€ Free Space: %d bytes (%.2f MB)", req.FreeSpace, float64(req.FreeSpace)/(1024*1024))
	if len(req.BlockIdsReport) > 0 {
		if len(req.BlockIdsReport) <= 10 {
			log.Printf("    â””â”€â”€ Block IDs: %v", req.BlockIdsReport)
		} else {
			log.Printf("    â””â”€â”€ Block IDs: %v... (total: %d blocks)", req.BlockIdsReport[:10], len(req.BlockIdsReport))
		}
	} else {
		log.Printf("    â””â”€â”€ Block IDs: [] (no blocks stored)")
	}

	// å‘é€å¿ƒè·³
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	resp, err := client.Heartbeat(ctx, req)
	if err != nil {
		log.Printf("Heartbeat failed, attempting to reconnect to leader: %v", err)
		// å°è¯•é‡è¿åˆ°æ–°çš„Leader
		if reconnectErr := s.reconnectToLeader(); reconnectErr != nil {
			return fmt.Errorf("failed to reconnect to leader: %w", reconnectErr)
		}

		// é‡æ–°åˆ›å»ºå®¢æˆ·ç«¯å¹¶é‡è¯•
		client = NewMetaServerServiceClient(s.metaClient)
		ctx, cancel = context.WithTimeout(context.Background(), 5*time.Second)
		defer cancel()

		resp, err = client.Heartbeat(ctx, req)
		if err != nil {
			return fmt.Errorf("failed to send heartbeat after reconnect: %w", err)
		}
	}

	// æ‰“å°å¿ƒè·³å“åº”æ•°æ®åˆ°æ§åˆ¶å°
	log.Printf("ğŸ’“ [HEARTBEAT RESPONSE] Commands received: %d", len(resp.Commands))
	if len(resp.Commands) > 0 {
		for i, cmd := range resp.Commands {
			actionName := "UNKNOWN"
			switch cmd.Action {
			case pb.Command_DELETE_BLOCK:
				actionName = "DELETE_BLOCK"
			case pb.Command_COPY_BLOCK:
				actionName = "COPY_BLOCK"
			}
			log.Printf("    â””â”€â”€ Command %d: %s (Block ID: %d)", i+1, actionName, cmd.BlockId)
			if len(cmd.Targets) > 0 {
				log.Printf("        â””â”€â”€ Targets: %v", cmd.Targets)
			}
		}
		go s.processCommands(resp.Commands)
	} else {
		log.Printf("    â””â”€â”€ No commands from MetaServer")
	}

	return nil
}

// processCommands å¤„ç†æ¥è‡ªmetaServerçš„å‘½ä»¤
func (s *EtcdClusterService) processCommands(commands []*pb.Command) {
	for _, cmd := range commands {
		if err := s.processCommand(cmd); err != nil {
			log.Printf("Failed to process command: %v", err)
		}
	}
}

// processCommand å¤„ç†å•ä¸ªå‘½ä»¤
func (s *EtcdClusterService) processCommand(cmd *pb.Command) error {
	switch cmd.Action {
	case pb.Command_DELETE_BLOCK:
		return s.processDeleteCommand(cmd.BlockId)

	case pb.Command_COPY_BLOCK:
		return s.processReplicateCommand(cmd.BlockId, cmd.Targets)

	default:
		return fmt.Errorf("unknown command action: %d", cmd.Action)
	}
}

// processDeleteCommand å¤„ç†åˆ é™¤å—å‘½ä»¤
func (s *EtcdClusterService) processDeleteCommand(blockID uint64) error {
	log.Printf("Processing delete command for block %d", blockID)

	if err := s.storageService.DeleteBlock(blockID); err != nil {
		return fmt.Errorf("failed to delete block %d: %w", blockID, err)
	}

	log.Printf("Successfully deleted block %d", blockID)
	return nil
}

// processReplicateCommand å¤„ç†å¤åˆ¶å—å‘½ä»¤ - ä»æºåœ°å€å¤åˆ¶æ•°æ®åˆ°æœ¬åœ°
func (s *EtcdClusterService) processReplicateCommand(blockID uint64, targets []string) error {
	if len(targets) == 0 {
		return fmt.Errorf("no source address provided for block %d replication", blockID)
	}

	sourceAddr := targets[0] // targets[0] æ˜¯æºåœ°å€
	log.Printf("Processing replicate command for block %d from source: %s", blockID, sourceAddr)

	// è¿æ¥åˆ°æºDataServer
	conn, err := grpc.Dial(sourceAddr, grpc.WithTransportCredentials(insecure.NewCredentials()))
	if err != nil {
		return fmt.Errorf("failed to connect to source %s: %w", sourceAddr, err)
	}
	defer conn.Close()

	client := pb.NewDataServerServiceClient(conn)

	// ä»æºåœ°å€è¯»å–å—æ•°æ®
	req := &pb.ReadBlockRequest{
		BlockId: blockID,
	}

	stream, err := client.ReadBlock(context.Background(), req)
	if err != nil {
		return fmt.Errorf("failed to read block %d from source %s: %w", blockID, sourceAddr, err)
	}

	var blockData []byte
	for {
		resp, err := stream.Recv()
		if err == io.EOF {
			break
		}
		if err != nil {
			return fmt.Errorf("failed to receive block data: %w", err)
		}
		blockData = append(blockData, resp.ChunkData...)
	}

	// å°†æ•°æ®å†™å…¥æœ¬åœ°å­˜å‚¨
	if err := s.storageService.WriteBlock(blockID, blockData); err != nil {
		return fmt.Errorf("failed to write block %d locally: %w", blockID, err)
	}

	log.Printf("Successfully replicated block %d from %s (%d bytes)", blockID, sourceAddr, len(blockData))
	return nil
}

// discoverLeader ä»etcdå‘ç°å½“å‰Leader
func discoverLeader(etcdClient *clientv3.Client) (string, error) {
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	// åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„sessionæ¥æŸ¥è¯¢leader
	session, err := concurrency.NewSession(etcdClient, concurrency.WithTTL(10))
	if err != nil {
		return "", fmt.Errorf("failed to create session: %w", err)
	}
	defer session.Close()

	// åˆ›å»ºelectionå¯¹è±¡
	election := concurrency.NewElection(session, "/minfs/metaServer/election")

	// æŸ¥è¯¢å½“å‰leader
	leaderResp, err := election.Leader(ctx)
	if err != nil {
		return "", fmt.Errorf("failed to query leader from election: %w", err)
	}

	if len(leaderResp.Kvs) == 0 {
		return "", fmt.Errorf("no leader found in election")
	}

	// è§£æleaderä¿¡æ¯: "nodeID:nodeAddr"
	leaderInfo := string(leaderResp.Kvs[0].Value)
	log.Printf("Found leader info: %s", leaderInfo)

	parts := strings.Split(leaderInfo, ":")
	if len(parts) < 2 {
		return "", fmt.Errorf("invalid leader info format: %s", leaderInfo)
	}

	nodeID := parts[0]
	nodeAddr := strings.Join(parts[1:], ":")

	log.Printf("Parsed leader - Node ID: %s, Address: %s", nodeID, nodeAddr)

	// éªŒè¯èŠ‚ç‚¹ä¿¡æ¯å­˜åœ¨
	nodeResp, err := etcdClient.Get(ctx, fmt.Sprintf("/minfs/metaServer/nodes/%s", nodeID))
	if err != nil {
		log.Printf("Warning: failed to get leader node info: %v", err)
		// å³ä½¿è·å–èŠ‚ç‚¹ä¿¡æ¯å¤±è´¥ï¼Œä¹Ÿå°è¯•ç›´æ¥ä½¿ç”¨åœ°å€
		return nodeAddr, nil
	}

	if len(nodeResp.Kvs) > 0 {
		// è§£æèŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯ä»¥è·å–å‡†ç¡®åœ°å€
		nodeInfo := string(nodeResp.Kvs[0].Value)
		log.Printf("Leader node info: %s", nodeInfo)

		var node struct {
			Addr string `json:"addr"`
		}

		if err := json.Unmarshal([]byte(nodeInfo), &node); err == nil && node.Addr != "" {
			log.Printf("Using leader address from node info: %s", node.Addr)
			return node.Addr, nil
		}
	}

	// ä½¿ç”¨ä»electionä¸­è§£æçš„åœ°å€
	log.Printf("Using leader address from election: %s", nodeAddr)
	return nodeAddr, nil
}

// reconnectToLeader é‡è¿åˆ°æ–°çš„Leader
func (s *EtcdClusterService) reconnectToLeader() error {
	// å‘ç°æ–°çš„Leader
	newLeader, err := discoverLeader(s.etcdClient)
	if err != nil {
		return fmt.Errorf("failed to discover new leader: %w", err)
	}

	if newLeader == s.currentLeader {
		return nil // æ²¡æœ‰å˜åŒ–
	}

	log.Printf("Leader changed from %s to %s, reconnecting...", s.currentLeader, newLeader)

	// å…³é—­æ—§è¿æ¥
	if s.metaClient != nil {
		s.metaClient.Close()
	}

	// åˆ›å»ºæ–°è¿æ¥
	ctx, cancel := context.WithTimeout(context.Background(),
		time.Duration(s.config.MetaServer.ConnectionTimeout)*time.Second)
	defer cancel()

	newConn, err := grpc.DialContext(ctx, newLeader,
		grpc.WithTransportCredentials(insecure.NewCredentials()),
	)
	if err != nil {
		return fmt.Errorf("failed to connect to new leader %s: %w", newLeader, err)
	}

	s.metaClient = newConn
	s.currentLeader = newLeader

	log.Printf("Successfully reconnected to new leader: %s", newLeader)
	return nil
}

// ä½¿ç”¨ç”Ÿæˆçš„MetaServerå®¢æˆ·ç«¯
func NewMetaServerServiceClient(conn *grpc.ClientConn) pb.MetaServerServiceClient {
	return pb.NewMetaServerServiceClient(conn)
}

// GetETCDClient è·å–etcdå®¢æˆ·ç«¯ï¼ˆç”¨äºä¼˜é›…å…³é—­æ—¶æ³¨é”€ï¼‰
func (s *EtcdClusterService) GetETCDClient() (*clientv3.Client, error) {
	if s.etcdClient == nil {
		return nil, fmt.Errorf("etcd client is not available")
	}
	return s.etcdClient, nil
}

// RevokeLease æ’¤é”€ç§Ÿçº¦ï¼ˆç”¨äºä¼˜é›…å…³é—­æ—¶æ³¨é”€ï¼‰
func (s *EtcdClusterService) RevokeLease() error {
	if s.lease == nil || s.leaseID == 0 {
		return fmt.Errorf("lease is not available")
	}

	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	_, err := s.lease.Revoke(ctx, s.leaseID)
	if err != nil {
		return fmt.Errorf("failed to revoke lease: %v", err)
	}

	log.Printf("Successfully revoked lease: %x", s.leaseID)
	return nil
}

// DeregisterFromETCD ä»etcdä¸­æ³¨é”€æœåŠ¡ - å¿«é€Ÿæ³¨é”€ç‰ˆæœ¬
func (s *EtcdClusterService) DeregisterFromETCD() error {
	log.Printf("Deregistering DataServer %s from etcd...", s.config.Server.DataserverId)

	ctx, cancel := context.WithTimeout(context.Background(), 3*time.Second)
	defer cancel()

	// åˆ é™¤æœåŠ¡æ³¨å†Œkey - ä½¿ç”¨ä¸æ³¨å†Œæ—¶ç›¸åŒçš„å‰ç¼€
	key := fmt.Sprintf("/dfs/dataServers/%s", s.config.Server.DataserverId)

	if _, err := s.etcdClient.Delete(ctx, key); err != nil {
		log.Printf("Failed to delete service key %s: %v", key, err)
		// å³ä½¿åˆ é™¤keyå¤±è´¥ï¼Œä¹Ÿç»§ç»­æ’¤é”€ç§Ÿçº¦
	} else {
		log.Printf("Successfully deleted service key: %s", key)
	}

	// æ’¤é”€ç§Ÿçº¦ - è¿™æ˜¯å…³é”®æ“ä½œï¼Œèƒ½ç«‹å³é‡Šæ”¾æ‰€æœ‰ç›¸å…³çš„key
	if s.lease != nil && s.leaseID != 0 {
		revokeCtx, revokeCancel := context.WithTimeout(context.Background(), 2*time.Second)
		defer revokeCancel()

		if _, err := s.lease.Revoke(revokeCtx, s.leaseID); err != nil {
			log.Printf("Failed to revoke lease: %v", err)
		} else {
			log.Printf("Successfully revoked lease: %x", s.leaseID)
		}
	}

	log.Printf("DataServer %s successfully deregistered from etcd", s.config.Server.DataserverId)
	return nil
}
